{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of  LDA parameters \n",
    "- Load  the csv files with the issues available in./datasets/issue/ \n",
    "- Generate text file to exectute https://github.com/amritbhanu/LDADE-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/issue\\all-issues_angularjs.arff.csv\n",
      "./datasets/issue\\all-issues_cakephp.arff.csv\n",
      "./datasets/issue\\all-issues_chartjs.arff.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clopezno\\anaconda\\envs\\textmining\\lib\\site-packages\\pandas\\core\\frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/issue\\all-issues_jquerytools.arff.csv\n",
      "./datasets/issue\\all-issues_rxjava.arff.csv\n",
      "./datasets/issue\\all-issues_vissoft14.arff.csv\n",
      "Number of files: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>'Fix #2275 s WebSocket version s server handsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>'Consider removing promise from write and add ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "2277  'Fix #2275 s WebSocket version s server handsh...\n",
       "2278  'Consider removing promise from write and add ..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load issue\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "#Read csv\n",
    "def loadCsvIssueFolder(path):\n",
    "    \"\"\"Load issue data from  csv files  and generate a \n",
    "    text file \n",
    "    Parameters:\n",
    "        ----------\n",
    "        path : folder path with csv file issue information. \n",
    "            id issue\n",
    "            title issue test\n",
    "            body issue test\n",
    "            commentsBodies test\n",
    "            'Label category: bug' text boolean is bug\n",
    "            isLabeled text boolean \n",
    "            isPullRequest text boolean\n",
    "     Returns:\n",
    "        -------  \n",
    "        _totalfile number of file read\n",
    "        dftotal dataframe with total issues   \n",
    "        \n",
    "    \"\"\"\n",
    "    _totalfile=0\n",
    "    dftotal=pd.DataFrame()\n",
    "    for filename in glob.glob(os.path.join(path, '*.csv')):        \n",
    "        print(filename)\n",
    "        df2=pd.read_csv(filename, error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "        df2[\"issuetext\"] = df2[\"title\"].map(str) + \" \" + \\\n",
    "        df2[\"body\"].map(str)\n",
    "        #df2[\"body\"].map(str)+ \" \" + \\\n",
    "        #df2['commentsBodies'].map(str)\n",
    "        _totalfile+=1\n",
    "        dftotal=dftotal.append(df2)\n",
    "    dftotal.rename(columns={\"'Label category: bug'\":'bug'}, inplace=True)    \n",
    "        #print(lprbt[len(lprbt)-1])\n",
    "    del dftotal['body']  \n",
    "    del dftotal['id'] \n",
    "    del dftotal['commentsBodies']\n",
    "    del dftotal['title'] \n",
    "    return _totalfile, dftotal\n",
    "\n",
    "def selectIssueAttributte(dfissue,attr_name):\n",
    "    dffiltered=pd.DataFrame()\n",
    "    dffiltered[\"text\"]=dfissue[\"issuetext\"]\n",
    "    dffiltered[\"attr\"]=dfissue[attr_name]\n",
    "    return dffiltered\n",
    "\n",
    "def texttoNumberIssue(df):\n",
    "    df = df.replace('jquerytools', 0).replace('Chart.js', 1).replace('netty', 2).replace('RxJava', 3).replace('cakephp', 4).replace('angular.js', 5)\n",
    "    df = df.replace('true', 1).replace('false', 0)\n",
    "    return df\n",
    "\n",
    "def concatIssueTextAttribute(df): \n",
    "    dfAtt=pd.DataFrame()\n",
    "    dfAtt[\"text\"]= df[\"text\"].map(str) + \" >>> \" + df[\"attr\"].map(str)\n",
    "    return dfAtt \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "totalfiles,df=loadCsvIssueFolder(path=\"./datasets/issue/\")   \n",
    "print(\"Number of files: {}\".format(totalfiles))\n",
    "df=texttoNumberIssue(df)\n",
    "#df = selectIssueAttributte(df,\"repo\")\n",
    "df = selectIssueAttributte(df,\"bug\")\n",
    "df = concatIssueTextAttribute(df)\n",
    "df.to_csv(\"./optimaizationdataset/LDAOptimizacionissue.txt\")\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PullRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/pullrequest\\reviews_angular.js_processed.csv\n",
      "./datasets/pullrequest\\reviews_appium_processed.csv\n",
      "./datasets/pullrequest\\reviews_cakephp_processed.csv\n",
      "./datasets/pullrequest\\reviews_Chart.js_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clopezno\\anaconda\\envs\\textmining\\lib\\site-packages\\pandas\\core\\frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/pullrequest\\reviews_elasticsearch_processed.csv\n",
      "./datasets/pullrequest\\reviews_Leaflet_processed.csv\n",
      "./datasets/pullrequest\\reviews_playframework_processed.csv\n",
      "./datasets/pullrequest\\reviews_WebFundamentals_processed.csv\n",
      "Number of files: 8 Number of instances in list: 4303\n",
      "Number of instance in dataframe 4303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>nan Fix typos. &gt;&gt;&gt; 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>nan Adding further tweaks to the article &gt;&gt;&gt; 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text\n",
       "621                            nan Fix typos. >>> 1\n",
       "622  nan Adding further tweaks to the article >>> 1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadCsvPullRequestFolder(path):\n",
    "    \"\"\"Load issue data from  csv files  and generate a \n",
    "    list with all issue\n",
    "    Parameters:\n",
    "        ----------\n",
    "        path : folder path with csv file issue information. \n",
    "            id issue\n",
    "            title issue test\n",
    "            body issue test\n",
    "            commentsBodies test\n",
    "            'Label category: bug' text boolean is bug\n",
    "            isLabeled text boolean \n",
    "            isPullRequest text boolean\n",
    "     Returns:\n",
    "        -------  \n",
    "        _totalfile number of file read\n",
    "        len(_liss) number of issue read\n",
    "        _liss list of total issues\n",
    "        dftotal dataframe with total issues   \n",
    "        \n",
    "    \"\"\"\n",
    "    _lpr=list()\n",
    "    _totalfile=0\n",
    "    dftotal=pd.DataFrame()\n",
    "    for filename in glob.glob(os.path.join(path, '*.csv')):        \n",
    "        print(filename)\n",
    "        df2=pd.read_csv(filename, error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "        df2[\"pull_request\"] = df2[\"pull_request_body\"].map(str) + \" \" +  df2[\"pull_request_title\"].map(str)\n",
    "       \n",
    "        \n",
    "        [_lpr.append(pr) for pr in df2.pull_request] \n",
    "        _totalfile+=1\n",
    "        dftotal=dftotal.append(df2)    \n",
    "        #print(lprbt[len(lprbt)-1])\n",
    "        #del dftotal['body']  \n",
    "        #del dftotal['id'] \n",
    "        #del dftotal['commentsBodies']\n",
    "        #del dftotal['title']\n",
    "    \n",
    "    return _totalfile, len(_lpr), _lpr, dftotal\n",
    "\n",
    "def selectPullRequetsAttributte(dfissue,attr_name):\n",
    "    dffiltered=pd.DataFrame()\n",
    "    dffiltered[\"text\"]=dfissue[\"pull_request\"]\n",
    "    dffiltered[\"attr\"]=dfissue[attr_name]\n",
    "    return dffiltered\n",
    "\n",
    "def texttoNumberPullRequets(df):\n",
    "    df = df.replace('angular.js', 0).replace('appium', 1).replace('cakephp', 2)\n",
    "    df = df.replace('elasticsearch', 3).replace('Chart.js', 4).replace('Leaflet', 5).replace('playframework', 6).replace('WebFundamentals', 7)\n",
    "    df = df.replace('true', 1).replace('false', 0)\n",
    "    return df\n",
    "\n",
    "def concatPullRequetsTextAttribute(df): \n",
    "    dfAtt=pd.DataFrame()\n",
    "    dfAtt[\"text\"]= df[\"text\"].map(str) + \" >>> \" + df[\"attr\"].map(str)\n",
    "    return dfAtt \n",
    "\n",
    "totalfiles,totalinstances,lprbt,df=loadCsvPullRequestFolder(path=\"./datasets/pullrequest/\")   \n",
    "print(\"Number of files: {} Number of instances in list: {}\".format(totalfiles,totalinstances))\n",
    "print(\"Number of instance in dataframe {}\".format(df.shape[0]))\n",
    "\n",
    "df = selectPullRequetsAttributte(df,\"pull_request_merged\")\n",
    "#df = selectPullRequetsAttributte(df,\"repository_name\")\n",
    "df =  texttoNumberPullRequets(df)\n",
    "df = concatPullRequetsTextAttribute(df)\n",
    "df.to_csv(\"./optimaizationdataset/LDAOptimizacionpullrequest.txt\")\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
